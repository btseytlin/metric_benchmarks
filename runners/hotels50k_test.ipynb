{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hotels50k import Hotels50kDataset, UseOriginalTestSplitManager\n",
    "from powerful_benchmarker.split_managers import IndexSplitManager\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning https://github.com/GWUvision/Hotels-50K into /data/thesis/Hotels-50K\n",
      "Repo already cloned\n",
      "Unpacking dataset archive\n",
      "Archive already unpacked\n",
      "Downloading train images\n",
      "Train images already loaded\n",
      "Downloading test images archive\n",
      "Archive already downloaded\n",
      "Archive already unpacked\n",
      "Creating symlinks\n",
      "Creating LMDB image folders\n",
      "LMDB file already exists\n",
      "LMDB file already exists\n",
      "LMDB file already exists\n",
      "LMDB file already exists\n",
      "Done downloading and setting up the dataset.\n",
      "Loading image folders\n",
      "Concatting dataset\n",
      "Getting labels\n"
     ]
    }
   ],
   "source": [
    "dataset = Hotels50kDataset(root='/data/thesis/Hotels-50K', target='hotels', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2330,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2274, 56)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.original_train_dataset.targets), len(dataset.original_test_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   7,    8,    9,   10,   11,   12,   13,   14,   15,   16,   17,\n",
       "          18,   19,   20,   21,   22,   23,   24,   25,   26,   27,   28,\n",
       "          29,   30,   31,   32,   33,   34,   35,   36,   37,   38,   39,\n",
       "        2278, 2279, 2280]),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dataset.labels==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(dataset.labels[0:100]) == [dataset[i][1] for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURR SPLIT SCHEME = UsingOriginalTest_Partitions4_0\n",
      "train len 1705\n",
      "val len 569\n",
      "test len 56\n",
      "train labels {19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83}\n",
      "val labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n",
      "test labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "CURR SPLIT SCHEME = UsingOriginalTest_Partitions4_1\n",
      "train len 1705\n",
      "val len 569\n",
      "test len 56\n",
      "train labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83}\n",
      "val labels {19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45}\n",
      "test labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "CURR SPLIT SCHEME = UsingOriginalTest_Partitions4_2\n",
      "train len 1706\n",
      "val len 568\n",
      "test len 56\n",
      "train labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83}\n",
      "val labels {45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "test labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "CURR SPLIT SCHEME = UsingOriginalTest_Partitions4_3\n",
      "train len 1706\n",
      "val len 568\n",
      "test len 56\n",
      "train labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63}\n",
      "val labels {63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83}\n",
      "test labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n"
     ]
    }
   ],
   "source": [
    "ds = dataset\n",
    "\n",
    "# first level of dictionary is transform type\n",
    "# second level consists of separate dataset objects for each split\n",
    "datasets = {\"eval\": {\"train\": ds,\n",
    "                    \"val\": ds,\n",
    "                    \"test\": ds}\n",
    "            }\n",
    "\n",
    "helper_split_manager = UseOriginalTestSplitManager()\n",
    "split_manager = IndexSplitManager(num_training_partitions=4, num_training_sets=4, helper_split_manager=helper_split_manager)\n",
    "\n",
    "split_manager.create_split_schemes(datasets)\n",
    "\n",
    "test_set = split_manager.get_dataset(\"eval\", \"test\")\n",
    "\n",
    "for name in split_manager.split_scheme_names:\n",
    "    split_manager.set_curr_split_scheme(name)\n",
    "    print(\"CURR SPLIT SCHEME =\", split_manager.curr_split_scheme_name)\n",
    "    print(\"train len\", len(split_manager.get_dataset(\"eval\", \"train\")))\n",
    "    print(\"val len\", len(split_manager.get_dataset(\"eval\", \"val\")))\n",
    "    print(\"test len\", len(split_manager.get_dataset(\"eval\", \"test\")))\n",
    "\n",
    "    print(\"train labels\", split_manager.get_label_set(\"eval\", \"train\"))\n",
    "    print(\"val labels\", split_manager.get_label_set(\"eval\", \"val\"))\n",
    "    print(\"test labels\", split_manager.get_label_set(\"eval\", \"test\"))\n",
    "    \n",
    "    assert set(split_manager.get_dataset(\"eval\", \"train\").indices).intersection(split_manager.get_dataset(\"eval\", \"val\").indices) == set()\n",
    "    assert set(split_manager.get_dataset(\"eval\", \"train\").indices).intersection(split_manager.get_dataset(\"eval\", \"test\").indices) == set()\n",
    "    assert set(split_manager.get_dataset(\"eval\", \"val\").indices).intersection(split_manager.get_dataset(\"eval\", \"test\").indices) == set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
